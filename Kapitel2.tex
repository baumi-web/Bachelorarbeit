\chapter{Aufbau der Testumgebung}
\section{Physische und Virtuelle Komponenten}
\subsection{Test-Hardware}
\textbf{Hardware für OpnSense:}\\
Für die Open-Source-Lösung OPNsense wurde im Sinne eines praxisnahen Vergleichs zunächst versucht, eine sehr ressourcenschonende Hardware-Plattform zu verwenden. Die initiale Wahl fiel auf einen kompakten Embedded-PC vom Typ PC Engines APU4, der in der Open-Source-Community häufig für den Aufbau von Routern und Firewalls genutzt wird. Die Installation auf diesem ''headless'' System (ohne Grafikschnittstelle) erfolgte über das offizielle serielle Image von OPNsense. Hierfür wurde ein bootfähiger USB-Stick mit dem Programm Rufus erstellt und die gesamte Installation über eine serielle Konsole via PuTTY gesteuert.\\

Bereits während der initialen Konfiguration des Intrusion Prevention Systems Suricata zeigte sich jedoch, dass die Hardware mit 4 GB RAM und der schwachen CPU mit 1GHz an ihre Leistungsgrenzen stieß und acuh ohne Laden der Regel-Sets zu einer CPU-Auslastung von 100\% führte. Das Laden der ausgewählten Regel-Sets mit über 35.000 Signaturen führte schließlich zu Absturz der gesamten Umgebung. Dies stellt einen stabilen Testbetrieb in Frage.\\

Um eine valide und performante Testdurchführung zu gewährleisten und die Fähigkeiten der OPNsense-Software fair bewerten zu können, wurde daher eine Umstellung auf eine leistungsfähigere Hardware-Plattform vorgenommen. Als finales Testsystem für OPNsense dient nun ein NRG Systems Mini-PC, der mit einem Intel(R) Core(TM) i7-4510U Prozessor, 8 GB DDR3L RAM und vier Gigabit-LAN-Anschlüssen ausgestattet ist. Diese Hardware-Aufwertung unterstreicht einen fundamentalen Aspekt der Open-Source-Philosophie: die Flexibilität, die Hardware an die wachsenden Anforderungen anzupassen, aber auch die Notwendigkeit einer sorgfältigen initialen Dimensionierung. Die Installation auf diesem System erfolgte unkompliziert über das Standard-ISO-Abbild.\\

\textbf{Hardware für Virtualisierung:}\\
Als Virtualisierungs-Host, der die zu schützenden Client-Systeme im LAN-Segment beherbergt, dient ein kompakter Mini-PC vom Typ HP EliteDesk 800 G4 DM 35W. Das System ist mit einer Intel(R) Core(TM) i5-8500T CPU, mit einem 16 GB DDR4-Arbeitsspeicher ausgestattet. Als primärer Datenspeicher für die virtuellen Maschinen wurde eine 256 GB NVMe SSD gewählt.(siehe Abbildung~\ref{fig:hardware-prox})\\

Die Entscheidung für eine SSD anstelle einer mechanischen Festplatte (HDD) war für die Performance der Testumgebung entscheidend. In einer Virtualisierungsumgebung greifen mehrere VMs gleichzeitig auf den Speicher zu, was zu einer hohen Anzahl paralleler Lese- und Schreibvorgänge führt. Während eine HDD diese Anfragen aufgrund ihres mechanischen Aufbaus mit einem beweglichen Schreib-/Lesekopf nur sequenziell, also Schritt für Schritt, abarbeiten kann, ist eine SSD in der Lage, Tausende dieser Anfragen parallel zu bedienen. Dieser Vorteil verhindert einen Input/Output-Flaschenhals, der für die nachfolgenden Tests zu ungenauen Ergebnissen führen könnte.\\

\textbf{Angreifer-Systems (Kali Linux):}\\
Als Angreifer-System, das im ungesicherten WAN-Segment der Testumgebung agiert, wurde ein dedizierter Laptop vom Typ DELL Latitude 5520 verwendet. Das Gerät ist mit einem Intel(R) Core(TM) i7 Prozessor, 16 GB RAM und einer 500 GB SSD ausgestattet. Diese Hardware-Ressourcen wurden als mehr als ausreichend bewertet, um die für die Tests notwendigen Analyse- und Angriffswerkzeuge performant auszuführen.\\

Die Installation des Betriebssystems erfolgte mittels der offiziellen Installer ISO-Datei von Kali Linux (Version 2025.2). Um den Laptop von diesem Abbild zu starten, wurde mit dem Programm ''Rufus'' ein bootfähiger USB-Stick erstellt. Während des Installationsprozesses wurde die gesamte 500 GB SSD für Kali Linux partitioniert und ein Standardbenutzer für die Durchführung der Tests angelegt.\\

Ein entscheidender Schritt war die Netzwerkkonfiguration. Da sich der Angreifer-Laptop in einem isolierten, physischen Netzwerksegment (WAN\_KALI) befindet, das nur mit dem WAN-Port der zu testenden Firewall verbunden ist, musste eine statische IP-Konfiguration vorgenommen werden. Dies wurde über die Kommandozeilen-Schnittstelle \textit{nmcli} realisiert. Dem System wurde die IP-Adresse 192.168.107.40 /24 zugewiesen. Als Gateway wurde die IP-Adresse des WAN\_KALI-Interfaces der Firewall (192.168.107.1) eingetragen, um eine korrekte Routing-Beziehung herzustellen.\\

Nach der erfolgreichen Grundinstallation wurde das System zunächst auf den neuesten Stand gebracht. Hierfür wurden über das Terminal die Befehle \textit{sudo apt update} und \textit{sudo apt full-upgrade -y} ausgeführt. Um sicherzustellen, dass alle für die geplanten Tests notwendigen Werkzeuge zur Verfügung stehen, wurde anschließend das Metapackage kali-linux-default installiert. Dieser Befehl (\textit{sudo apt install -y kali-linux-default}) rüstet das System mit der Standard-Sammlung an Penetration-Testing-Tools aus, die unter anderem das Metasploit Framework, den Portscanner Nmap sowie den Paketgenerator hping3 umfasst.\\


\subsection{Virtualisierungssoftware}

Als Fundament für die Virtualisierung der Client-Systeme, die das LAN-Segment der Testumgebung abbilden, wurde die Open-Source-Plattform Proxmox Virtual Environment (VE) in der Version 8.2 gewählt. Die Entscheidung für einen dedizierten Bare-Metal-Hypervisor anstelle einer Desktop-Virtualisierungslösung wie VirtualBox wurde getroffen, um eine höhere Performance durch den direkten, ressourcenschonenden Zugriff auf die Hardware des Test-Laptops zu gewährleisten. Proxmox VE bot zudem die notwendige, granulare Kontrolle über die virtuelle Vernetzung und eine integrierte Snapshot-Funktionalität. Dieses Feature war für die Durchführung der Tests essenziell, da sie es ermöglicht, die Testsysteme vor jedem Testdurchlauf in einen definierten, sauberen Ausgangszustand zurückzusetzen und so für reproduzierbare Ergebnisse zu sorgen.\\

Die Installation erfolgte über das offizielle ISO-Abbild direkt auf dem dafür vorgesehenen Test-Laptop, der ausschließlich als Host für die Client-Systeme dient. Hierfür wurde zunächst ein bootfähiger USB-Stick erstellt. Der Installationsprozess selbst gestaltet sich unkompliziert, erforderte jedoch bei der Netzwerkkonfiguration einzelne manuelle Anpassungen. Da der Laptop als Server im LAN-Segment hinter der physischen Firewall agieren sollt, muss eine statische IP-Adresse, Subnetzmaske, Gateway (die LAN-IP-Adresse der Firewall), sowie der DNS-Server manuell in der Installationsroutine hinterlegt werden.\\

\textbf{Aufgetretenes Problem:}\\
Bei der Installation  traten initial Konnektivitätsprobleme auf. Anschließend war die webbasierte Verwaltungsoberfläche von einem anderen Rechner im Netzwerk nicht erreichbar, obwohl die Netzwerkinformationen im Installer korrekt eingegeben wurden. Eine Analyse über die Kommandozeile des Servers zeigte, dass die Netzwerkkonfigurationsdatei ''\textit{/etc/network/interfaces}'' nicht korrekt geschrieben wurde. Dieses Problem konnte durch eine manuelle Bearbeitung der Datei direkt auf der Server-Konsole und einen anschließenden Neustart des Netzwerk-Dienstes mittels ''\textit{systemctl restart networking.service}'' behoben werden. Erst danach war der Proxmox-Host unter der korrekten statischen IP-Adresse erreichbar und die weitere Konfiguration konnte über die Weboberfläche erfolgen.\\

Ein zentrales Konzept für den Aufbau der Testumgebung in Proxmox ist dabei die Verwendung von virtuellen Bridges. Für den in dieser Arbeit realisierten Aufbau wurde eine einzige virtuelle Bridge (vmbr0) konfiguriert, die direkt an die physische Netzwerkkarte des Proxmox-Laptops gekoppelt ist. Das physische LAN-Kabel verbindet diese Netzwerkkarte mit dem LAN-Port der zu testenden, physischen Firewall. Alle in Proxmox erstellten Client-VMs werden dann mit ihren virtuellen Netzwerkkarten an diese Bridge angeschlossen, wodurch sie zusammen ein virtuelles LAN-Segment bilden. Dieses Segment ist physisch direkt und ausschließlich mit einem geschützten LAN-Port der Firewall verbunden.\\


\subsection{Virtuelle Maschinen (VMs)}

Die Client-Systeme, die das geschützte LAN-Segment bilden, sowie ein interner Angreifer wurden vollständig innerhalb der Proxmox Virtual Environment virtualisiert. Der grundlegende Prozess zur Erstellung jeder VM umfasst das Hochladen der entsprechenden ISO-Abbilder in den lokalen Speicher des Proxmox-Hosts. Anschließend wurden die virtuellen Maschinen über den Installationsassistenten mit den für ihre jeweilige Rolle und ihr Betriebssystem passenden Hardwareressourcen konfiguriert.\\

\textbf{Ubuntu Desktop:}\\
Um repräsentative Linux-Clients im geschützten LAN abzubilden, wurden zwei identische VMs mit Ubuntu 24.04 LTS Desktop erstellt. Diese dienen als Ziele für Angriffe und zur Durchführung von Tests wie der Malware-Erkennung oder der Überprüfung von Filterregeln. Beiden VMs wurden jeweils 4 CPU-Kerne, 4 GiB Arbeitsspeicher und eine 50 GiB Festplatte zugewiesen. Um sie im geschützten LAN-Segment zu platzieren, wurden beide VMs mit ihren virtuellen Netzwerkkarten an die interne Bridge \textit{vmbr1} angebunden.(siehe Abbildung~\ref{fig:ubuntu-hardware})\\

\textbf{Kali-Linux:}\\
Zur Simulation eines internen Angriffs wurde eine VM mit Kali Linux aufgesetzt, die ein kompromittiertes Endgerät im LAN repräsentiert. Der VM wurden 4 CPU-Kerne, 4 GiB Arbeitsspeicher und eine 50 GiB Festplatte zugewiesen. Entscheidend für diesen Testfall wurde die Netzwerkkarte der VM, identisch zu den Client-Systemen, an die interne Bridge vmbr1 angebunden. (siehe Abbildung~\ref{fig:kali-hardware})\\
Dieser Aufbau eines flachen Netzwerks dient der praktischen Demonstration der Grenzen des reinen Perimeterschutzes. Wie erwartet, kann die physische Firewall den direkten Verkehr zwischen den VMs auf derselben Bridge nicht einsehen oder blockieren. Ein erfolgreicher interner Exploit demonstriert somit die kritische Schutzlücke, die bei alleiniger Konzentration auf den Perimeterschutz entsteht und unterstreicht die Notwendigkeit weiterführender Sicherheitskonzepte wie Zero-Trust und interner Netzwerksegmentierung.\\

\textbf{Windows 11:}\\
Zur Simulation einer typischen Workstation in einem Unternehmensumfeld wurde eine VM mit Microsoft Windows 11 Enterprise aufgesetzt. Entsprechend den höheren Anforderungen des Betriebssystems wurden dieser VM 4 CPU-Kerne, 8 GiB Arbeitsspeicher und eine 70 GiB Festplatte zugewiesen. Auch diese VM wurde an die Bridge \textit{vmbr1} angebunden, um sie im LAN zu positionieren.(siehe Abbildung~\ref{fig:win11-hardware})\\

\textbf{Besonderheit bei der Windows-Installation:}\\
Aufgrund der spezifischen Anforderungen von Windows 11 mussten in den Systemeinstellungen der VM das BIOS auf OVMF (UEFI) umgestellt und ein virtuelles Trusted Platform Module (TPM) 2.0 sowie eine EFI-Disk hinzugefügt werden.
 Im Gegensatz zu den Linux-basierten Systemen trat bei der Installation zudem ein Problem auf, da der Windows-Installer standardmäßig keine Treiber für die paravirtualisierte VirtIO-Hardware enthält. Dadurch konnte im Partitionierungs-Schritt der Installation keine Festplatte erkannt werden. Um dieses Problem zu lösen, musste die virtio-win.iso-Datei mit den Gast-Treibern heruntergeladen und der VM als zweites, virtuelles CD/DVD-Laufwerk zugewiesen werden. Im Windows-Setup konnten dann die Speichertreiber aus dem Verzeichnis \path{\viostor\w11\amd} manuell geladen werden, woraufhin die virtuelle Festplatte erkannt wurde und die Installation fortgesetzt und abgeschlossen werden konnte.

\section{Netzwerkarchitektur}
\subsection{Netzwerkarchitektur Testumgebung OPNsense}
Die Netzwerktopologie gliedert sich in drei zentrale Bereiche. Über Port 4 der Firewall besteht die Anbindung an das Heimnetzwerk. Dieses Interface ist als WAN-Schnittstelle konfiguriert und bezieht seine IP-Adresse per DHCP, wodurch eine direkte Verbindung ins Internet gewährleistet ist. An Port 1 wurde der Mini-PC angeschlossen, auf dem Proxmox VE betrieben wird. Dieser dient als Hostsystem für die internen Client-VMs (Windows und Ubuntu). Die OPNsense agiert in diesem Segment als DHCP-Server und vergibt Adressen im Subnetz 192.168.101.0/24. In diesem Netz besitzt die Firewall selbst die Adresse 192.168.101.1, während der Proxmox-Host unter 192.168.101.10:8006 erreichbar ist.\\
Ein weiteres Teilnetz wurde über Port 2 realisiert und als Angreifernetz konfiguriert. Hier befindet sich ein physisch installierter Laptop mit Kali Linux, der über die Adresse 192.168.107.20 in das Subnetz 192.168.107.0/24 eingebunden ist. Die OPNsense übernimmt in diesem Netz die Gateway-Funktion und ist unter der Adresse 192.168.107.1 erreichbar. Dieses Segment dient ausschließlich der Durchführung von Angriffssimulationen auf die im Clientnetz befindlichen Systeme.\\
Durch diese Strukturierung konnte eine realistische Testumgebung geschaffen werden, die produktiven Netzwerkverkehr (Clientnetz - WAN) ebenso wie gezielte Angriffe (Kali - Clientnetz) abbildet. Die OPNsense übernimmt dabei die zentrale Sicherheitsfunktion und steht als einziger Inspektionspunkt in Mitten der Testumgebung.

\subsection{Netzwerkarchitektur Testumgebung FortiGate VM}
Diese Testumgebung wurde vollständig virtualisiert in Proxmox VE aufgebaut. Im Zentrum steht eine FortiGate-VM, die als virtuelle Firewall und IPS-Komponente zwischen den verschiedenen logischen Netzsegmenten vermittelt. Alle beteiligten Systeme, sowohl die Firewall als auch die angeschlossenen Test-Clients, laufen in diesem Fall als virtuelle Maschinen auf demselben Proxmox-Host.\\
Die FortiGate-VM ist mit drei virtuellen Netzwerkschnittstellen ausgestattet, die jeweils unterschiedlichen in Proxmox definierten Bridges zugeordnet sind. Das WAN-Interface (port1) ist mit der Bridge vmbr0 verbunden und erhält per DHCP eine Adresse aus dem Heimnetzwerk, wodurch die Internetanbindung gewährleistet wird. Das LAN-Interface (port2) ist an die Bridge vmbr1 gekoppelt und bildet das interne Clientnetz mit der Adresse 192.168.10.1/24. In diesem Segment befinden sich die Client-VMs (Windows und Ubuntu), die über den auf der FortiGate eingerichteten DHCP-Dienst automatisch mit Adressen versorgt werden. Das dritte Interface (port3) wurde der Bridge vmbr2 zugewiesen und als separates Kali-Testnetz (192.168.20.1/24) konfiguriert, in dem eine Kali-Linux-VM für die Durchführung gezielter Angriffe betrieben wird.

\section{Konfiguration der Firewalls und IPS-Systeme}
\subsection{Konfiguration der FortiGate VM}
Die Bereitstellung der FortiGate-VM erfolgte in mehreren Schritten, die sowohl die Einrichtung auf dem ProxmoxVE Server als auch die anschließende Konfiguration innerhalb des FortiGate-Betriebssystems umfasst. Ziel war die Integration der virtuellen Firewall in die zuvor entworfene Testumgebung, bestehend aus einem LAN-Segment für Clients, einem separaten Kali-Linux-Segment zur Durchführung von Angriffssimulationen sowie einer WAN-Anbindung.\\

Für die Installation der FortiGate-VM wurde ein von Fortinet bereitgestelltes Systemabbild (fortios.qcow2) genutzt. Da dieses Abbild zunächst auf den Hypervisor übertragen werden musste, erfolgte der Zugriff auf den Proxmox-Host über PuTTY. Für die eigentliche Übertragung der Datei wurde das in PuTTY integrierte Tool pscp (PuTTY Secure Copy) eingesetzt. Der Kopiervorgang wurde über den Befehl \verb| pscp fortios.qcow2 root@192.168.100.14:/var/lib/vz/images/| durchgeführt, wobei das FortiOS-Abbild vom lokalen Rechner in das von Proxmox verwendete Standardverzeichnis für virtuelle Festplatten (/var/lib/vz/images/) übertragen wurde.\\
Im Anschluss daran wurde über die Weboberfläche von ProxmoxVE eine neue VM erstellt. Während der Konfiguration wurde darauf verzichtet, eine leere Standardfestplatte anzulegen. Stattdessen wurde das zuvor hochgeladene QCOW2-Abbild direkt als Systemfestplatte eingebunden. Auf diese Weise startet die VM unmittelbar mit dem originalen FortiOS-System und eine separate Installation ist nicht mehr nötig.\\

Nach der erfolgreichen Einbindung des Systemabbilds wurde die virtuelle Maschine über die Proxmox-Weboberfläche erstellt und konfiguriert. Dabei wurde der Maschinentyp auf q35 gesetzt, da dieser gegenüber älteren Varianten eine verbesserte Hardwarekompatibilität sowie höhere Performance bietet. Als Festplatten-Controller wurde VirtIO-SCSI gewählt, um eine optimale Leistung zu erzielen.\cite{ProxmoxVE}\\
Ein zentrales Element der Einrichtung war die Konfiguration der Netzwerkschnittstellen. Dazu wurden in Proxmox drei virtuelle Bridges erstellt, die jeweils einem logischen Teilnetz der Testumgebung entsprechen:
\begin{itemize}
	\item vmbr0: Anbindung an das Heimnetzwerk und damit an das WAN
	\item vmbr1: internes LAN für die Client-Systeme
	\item vmbr2: separates Testnetz für die Kali-Linux-VM
\end{itemize}
Diese Bridges wurden anschließend jeweils  den virtuellen Netzwerkkarten der FortiGate-VM zugeordnet. Damit war eine klare Trennung der Netzsegmente gewährleistet, die die spätere Abbildung realistischer Sicherheitsmechanismen erlaubt.(siehe Abbildung~\ref{fig:fortivm-hardware})\\

Nach Abschluss der Konfiguration konnte die VM gestartet werden. Der erste Zugriff erfolgte über die in Proxmox integrierte serielle Konsole, welche unmittelbar die Kommandozeile von FortiOS bereitstellt. Zunächst wurde das vom System geforderte Standardpasswort geändert, um die Basissicherheit der VM zu gewährleisten. Anschließend wurden die einzelnen Interfaces aktiviert und mit IP-Adressen versehen. Dabei wurde port1 als WAN-Schnittstelle definiert und über DHCP an das Heimnetz angebunden. Für das interne LAN (port2) wurde die statische Adresse 192.168.10.1/24 vergeben, während das Kali-Testnetz (port3) die statische Adresse 192.168.20.1/24 erhielt.(siehe Abbildung~\ref{fig:fortivm-config-init})

Des Weiteren wurde auf den internen Schnittstellen ein DHCP-Server eingerichtet, sodass sowohl die Client-Systeme im LAN als auch die Kali-VM automatisch mit IP-Adressen versorgt werden konnten. Für die Verwaltung der FortiGate-VM wurden auf dem LAN-Interface zusätzlich die Protokolle HTTPS, SSH und ICMP freigeschaltet, wodurch sowohl die spätere grafische Konfiguration über die Weboberfläche als auch eine kontinuierliche Erreichbarkeit zur Systemdiagnose sichergestellt wurde.(siehe Abbildung~\ref{fig:fortivm-config-init})\\

Für die Lizenzierung war zunächst eine Registrierung im Fortinet-Support-Portal erforderlich, da die Lizenzdatei dort für die spezifische VM-Instanz bereitgestellt wird.

Die heruntergeladene Lizenzdatei (.lic) wurde anschließend über die Weboberfläche der FortiGate-VM hochgeladen.
Für die vollständige Aktivierung und Nutzung der sicherheitsrelevanten Dienste (IPS, Antivirus-Scanning, Webfiltering und Application Control) ist zwingend eine Kommunikation mit den Fortinet-Update-Servern erforderlich. Erst über diese Verbindung wird die Gültigkeit der Lizenz überprüft und es werden aktuelle Signaturdatenbanken heruntergeladen.

Da im Rahmen der Grundkonfiguration das WAN-Interface (port1) bereits per DHCP mit dem Heimnetz verbunden war und somit Zugriff auf das Internet besitzt, konnte die FortiGate-VM nach dem Upload der Lizenzdatei unmittelbar eine Verbindung zu den FortiGuard-Servern herstellen. Dadurch wurde die Lizenz automatisch aktiviert und die aktuellen Sicherheitsupdates heruntergeladen, was die VM in den vollen Funktionsumfang versetzte.\\

Abbildung~\ref{fig:forti-WANroute} zeigt die definierte Default-Route, die sämtlichen ausgehenden Verkehr aus dem LAN über das WAN-Interface leitet. Zusätzlich wurde auf der FortiGate die DNS-Weiterleitung konfiguriert. Dadurch erhielten die Clients über DHCP automatisch die interne IP-Adresse der FortiGate als DNS-Server.\\

Im nächsten Schritt erfolgte die Erstellung zentraler Firewall-Policies. Um in den zu erstellenden Regeln die passenden Adressbereiche zu wählen, wurde für die LAN-Subnetz und KALI-Subnetz entsprechend adressen erstellt.(siehe Abbildung~\ref{fig:forti-LAN-addr}, \ref{fig:forti-Kali-addr}) Zunächst wurde eine Policy ''LAN\_to\_WAN'' eingerichtet, die es dem LAN ermöglicht, ins Internet zu kommunizieren. Hierbei ist es besonders wichtig das NAT zu aktivieren.(siehe Abbildung~\ref{fig:forti-LAN-WAN-P01}) Auch Sicherheitsprofile wie Antivirus, Webfilter, IPS und SSL Inspection wurden aktiviert. Dabei wurden die default Profile der FortiGate ausgewählt. Im späteren Verlauf wird noch ein eigenes IPS-Profil und SSL-Inspection definiert und in die erstellten Policies übernommen.\\
Anschließend wurde die Regel erstellt, die den Verkehr vom Kali-Netz zum LAN zulässt. Diese Policy diente dazu, gezielt Angriffe aus der Kali-VM gegen die im LAN befindlichen Testsysteme zu initiieren und deren Abwehrmechanismen durch die FortiGate-VM zu überwachen.(siehe Abbildung~\ref{fig:forti-Kali-LAN-P01}) Analog dazu wurde eine weitere Policy ''KALI\_to\_WAN'' erstellt, die es der Kali-VM erlaubt, auf das Internet zuzugreifen, um notwendige Tools für die Tests zu installieren.\\

Zur Verbesserung der Angriffserkennung wurde ein eigenes IPS-Profil erstellt. Dieses wurde nicht als Standardprofil übernommen, sondern individuell konfiguriert, um die Testumgebung gezielt abzusichern. Innerhalb des IPS-Profils wurden Filter gesetzt, die sowohl Server- als auch Client-Signaturen mit hoher und kritischer Schwere (Severity) umfassten. Die Aktion wurde auf ''Block'' gesetzt, wodurch erkannte Angriffe unmittelbar unterbunden werden. (siehe Abbildung~\ref{fig:forti-IPS-sensor})\\

Darüber hinaus wurde zur Analyse verschlüsselter Verbindungen ein eigenes SSL-Inspection-Profil definiert. Im Rahmen dieses Profils kam die Option ''Full SSL Inspection'' zum Einsatz, sodass sämtliche verschlüsselte Verbindungen auf Anwendungsebene entschlüsselt und überprüft werden können. Als Zertifizierungsstelle wurde das von Fortinet bereitgestellte Zertifikat Fortinet\_CA\_SSL hinterlegt, welches auf allen Test-Clients installiert wurde, um Zertifikatswarnungen beim Zugriff auf HTTPS-Dienste zu vermeiden. Zusätzlich wurden ungültige, abgelaufene oder widerrufene Zertifikate standardmäßig blockiert, um potenzielle Risiken durch kompromittierte Verbindungen auszuschließen. Die Inspektion erstreckt sich auf alle sicherheitsrelevanten Protokolle (HTTPS, SMTPS, POP3S, IMAPS, FTPS, DNS over TLS), sodass neben Webverkehr auch E-Mail- und Dateitransfers überwacht werden können. Um die Nutzbarkeit der Testumgebung sicherzustellen und den Praxisbezug beizubehalten, wurden bestimmte sensible Kategorien, wie ''Finance and Banking'' oder ''Personal Privacy'' von der Entschlüsselung ausgenommen, da eine Aufschlüsselung dieser Inhalte sowohl aus rechtlicher Perspektive als auch in Hinblick auf den Datenschutz problematisch wäre.(siehe Abbildung~\ref{fig:forti-SSL})\\

Nachdem nun diese selbst-definierten Profile angelegt wurden, wurden sie den entsprechenden Policies zugewiesen. (siehe Abbildung~\ref{fig:forti-Policies02})


\subsection{Konfiguration von OPNsense}

Die Konfiguration der OPNsense-Firewall wurde in zwei logischen Phasen durchgeführt. Zunächst wurde eine initiale Einrichtungsphase durchlaufen, in der dem System temporär ein Zugang zum Internet gewährt wurde. Dies war notwendig, um das Basissystem auf den neuesten Stand zu bringen, das für die Tests erforderliche Intrusion-Prevention-System-Plugin zu installieren und die benötigten Regel-Sets herunterzuladen. Nach Abschluss dieser Vorbereitungen wurde das System in die finale, isolierte Testkonfiguration überführt, in der es ausschließlich als Gateway zwischen dem Angreifer-Netz (WAN) und dem Client-Netz (LAN) fungiert.\\

\textbf{Konfiguration des IPS (Suricata):}\\
Die zentrale Schutzkomponente, das IPS, wurde durch die Installation des Plugins os-suricata über die Firmware-Verwaltung von OPNsense implementiert. Die anschließende Konfiguration des Dienstes erfolgte in mehreren Schritten. Zuerst wurden im Reiter ''Download'' die Regel-Sets ausgewählt und heruntergeladen.\\

Für die Konfiguration des Intrusion Prevention Systems wurde eine gezielte Auswahl an Regel-Sets getroffen, anstatt alle verfügbaren Regeln zu aktivieren. Dieser Ansatz verfolgt das Ziel, eine hohe Erkennungsrate für die relevanten Bedrohungsszenarien zu gewährleisten und gleichzeitig die Systemlast sowie das Risiko von Falschmeldungen (False-Positives) zu minimieren. Die Auswahl basiert hierbei auf einer mehrschichtigen Strategie.\\
Als Grundschutz dienen ausgewählte Kategorien des weit verbreiteten "ET Open"-Regel-Sets. Dabei wurden die Kategorien aktiviert, die direkt die in dieser Arbeit untersuchten Bedrohungen abdecken: Erkennung von Software-Ausnutzungen, Schadsoftware-Kommunikation, Denial-of-Service-Angriffen und Netzwerk-Scans. Ergänzt wurde diese Auswahl um die Kategorien ''attack\_response'' und ''compromised'', die Signaturen für bereits erfolgte Kompromittierungen enthalten.\\
Dieser breite, signaturbasierte Schutz wird durch spezialisierte, reputationsbasierte Bedrohungslisten des Non-Profit-Projekts abuse.ch ergänzt. Konkret wurden die ''SSL Fingerprint Blacklist'' und der ''ThreatFox''-Feed aktiviert. Diese Listen enthalten keine generischen Angriffsmuster, sondern blockieren aktiv die Kommunikation mit in Echtzeit identifizierten, bösartigen Command-and-Control-Servern.

Die Konfiguration der OPNsense-Firewall wurde in zwei logischen Phasen durchgeführt. Zunächst wurde eine initiale Einrichtungsphase durchlaufen, in der dem System temporär ein Zugang zum Internet gewährt wurde. Dies war notwendig, um das Basissystem auf den neuesten Stand zu bringen, das für die Tests erforderliche Intrusion-Prevention-System-Plugin zu installieren und die benötigten Regel-Sets herunterzuladen. Nach Abschluss dieser Vorbereitungen wurde das System in die finale, isolierte Testkonfiguration überführt.\\

Die Konfiguration der Netzwerkschnittstellen erfolgte gemäß der in Kapitel 3.2 definierten logischen Netzwerkarchitektur. Der LAN-Schnittstelle wurde ihre Rolle als Gateway für das interne Netz zugewiesen und unter Services > DHCPv4 > [LAN] mit einem DHCP-Server zur automatischen Adressvergabe an die Client-VMs ausgestattet. Die WAN\_KALI-Schnittstelle wurde als statischer Endpunkt für das Angreifer-Netz konfiguriert, wobei die systemeigenen Filter ''Block private networks'' und ''Block bogon networks'' für diese Schnittstelle bewusst deaktiviert wurden, da der angeschlossene Angreifer eine private IP-Adresse verwendet.\\

\textbf{Konfiguration des IPS (Suricata):}\\
Die zentrale Schutzkomponente, das IPS, wurde durch die Installation des Plugins os-suricata implementiert. Nach der Auswahl und dem Download der Regel-Sets ''ET Open'' und ''abuse.ch'' wurde der Dienst im Reiter ''Settings'' global aktiviert, in den "Inline Mode" (IPS) versetzt und angewiesen, den Verkehr auf der WAN\_KALI-Schnittstelle zu überwachen. Um die Signaturen scharfzuschalten, wurde im Reiter "Policy" eine übergeordnete Richtlinie erstellt, die alle heruntergeladenen Regel-Sets anwies, bei einem Treffer die Standard-Aktion drop (aktiv blockieren) auszuführen.(siehe Abbildung~\ref{fig:ipsopn1})\\

Zur Vollständigkeit sei erwähnt, dass OPNsense neben der verwaltung über die grafische Benutzeroberfläche auch erfahrenen Anwendern die Möglichkeit bietet, die IPS-Richtlinien direkt über die Kommandozeile zu verwalten. In den Konfigurationsdateien von Suricata können benutzerdefinierte Richtlinien geschrieben werden, um beispielsweise sehr granulare Ausnahmen zu definieren oder das Verhalten für einzelne Signaturen gezielt zu modifizieren. Für die im Rahmen dieser Arbeit durchgeführten Tests wurde auf diese Methode verzichtet, da der Fokus auf der standardmäßigen und für die meisten Anwender relevanten Konfiguration über die Weboberfläche lag.\\

Zuletzt wurden die Firewall-Regeln unter Firewall > Rules erstellt. Da OPNsense einer ''Default Deny''-Strategie folgt, bei der jeglicher Verkehr, der nicht explizit erlaubt ist, blockiert wird, mussten spezifische Regeln erstellt werden, um den für die Tests notwendigen Datenfluss zu ermöglichen.\\
Für den eingehenden Testverkehr wurde auf dem WAN\_KALI-Interface eine Regel angelegt, die den gezielten Angriff vom Kali-Laptop auf die zu testenden Dienste der Client-VMs erlaubt. Der Zweck dieser Regel ist es, den Angriffsverkehr kontrolliert an die IPS-Engine weiterzuleiten, die auf diesem Interface den Verkehr analysiert.\\

Für den ausgehenden Verkehr vom LAN ins WAN wurde aus Gründen der Vereinfachung im Testlabor eine "Pass-All"-Regel erstellt, die dem gesamten LAN net den Zugriff auf jedes beliebige Ziel erlaubt.\\

\textbf{Hinweis:}
Es ist wichtig zu betonen, dass dies keine ''Best-Practice''-Konfiguration für eine produktive Umgebung darstellt. In einem realen Unternehmensnetzwerk würde an dieser Stelle ein wesentlich restriktiveres Regelwerk nach dem Prinzip der geringsten Rechte zum Einsatz kommen. Dabei würden typischerweise Adress-Objekte oder Gruppen (z.B. ''Buchhaltung'', ''Entwicklung'', ''Administration'', Drucker'') erstellt werden. Anschließend würden für jede dieser Gruppen granulare Regeln definiert, die nur den Zugriff auf die für ihre Arbeit absolut notwendigen Dienste und Ports erlauben (z.B. nur HTTP und HTTPS für Standard-Nutzer). Alle anderen ausgehenden Verbindungen würden durch die implizite ''Deny-All''-Regel am Ende des Regelwerks blockiert. Für die klar definierte Testumgebung dieser Arbeit wurde auf diese granulare Aufteilung verzichtet, um den Fokus auf die Inbound-IPS-Funktionalität zu legen.


Damit das IPS auch in die Pakete von HTTPS Taffic schauen kann, benötigt man SSL-Inspection. Dafür kann man direkt auf der OPNsense das Plugin Squid herunterladen. Dies ist ein Service, der einen Web Proxy bereitstellt. Damit nun der Verkehr von den Clients nicht mehr direkt in das Wan gelangt, sondern an den Proxy geleitet wird, muss man entsprechende Network-Address-Translation (NAT) -Regeln erstellen. Der Squid Web Proxy hört per Default auf den Port 3128/3129. (siehe Abbildung~\ref{fig:squidproxy}) Damit wurden 2 NAT-Regeln erstellt, die den Verkehr über Port 80 und 443 auf Port 3128 und 3129 leiten. (siehe Abbildung~\ref{fig:proxynat})\\
Außerdem muss man ein Zertifikat erstellen, den Proxy dieses Zertifikat als Autorität zuweisen und das Zertifikat auf allen Clients installieren.
Anschließend wurde durch Testen bestätigt, dass die Clients das installierte Zertifikat nutzen. Um jedoch auch aussagekräftig sagen zu können, ob der Verkehr nun über den Proxy läuft, musste man in den Log-Datei des Plugins Squid schauen. Dafür kann man sich in der Konsole auf der OPNsense anmelden und mit dem Befehl \verb |tail -f /var/log/squid/access.log| live die letzten Zeilen der log-Datei sehen.(siehe Abbildung~\ref{fig:proxylog}) Dies bestätigte, dass der gesamte Verkehr über den Web Proxy geht.